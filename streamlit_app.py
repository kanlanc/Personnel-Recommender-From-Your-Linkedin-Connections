# -*- coding: utf-8 -*-
"""Useful Linkedin Connects.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1onyGXzQzMW8exK4rHVQ9WezidUxEAqLI
"""



import os
import pandas as pd


import pandas as pd




from langchain.chat_models import ChatAnthropic
# from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.agents import Tool
from langchain.agents import AgentType
from langchain.utilities import SerpAPIWrapper
from langchain.agents import initialize_agent
from langchain.memory import ConversationBufferMemory
from langchain.llms import OpenAI
from langchain.chains.qa_with_sources import load_qa_with_sources_chain
from langchain.docstore.document import Document
import requests
from langchain.prompts.chat import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
    AIMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain import PromptTemplate
from langchain import LLMChain
import cohere
import streamlit as st

os.environ['username'] = 'itsmethefounder@outlook.com'
os.environ['password'] = "Tech4Life!"
os.environ['ANTHROPIC_API_KEY'] = "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"
os.environ['LANGCHAIN_API_KEY'] = "ls__0aa97ffdedf342068430ab83273564fd"


openai_api_key = ""
ANTHROPIC_API_KEY=""
SERPAPI_API_KEY=""


LANGCHAIN_API_KEY="ls__0aa97ffdedf342068430ab83273564fd"
LANGCHAIN_TRACING_V2=True
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
LANGCHAIN_PROJECT="Foodsmith"


cohere_api_key = "5GIQYhLSWrnXOprlPqJSwKu6l7awxtBfi26R9c7c"


co = cohere.Client(cohere_api_key)
claude = ChatAnthropic(temperature=0)
cohere = ChatAnthropic(temperature=0)
gpt = ChatAnthropic(temperature=0)

user_connections_list = pd.read_csv("enriched_data_linkedin_data_connections.csv")
user_query = "Give me people who worked in the XR industry"

template = """Answer the question based on the context below. If the
question cannot be answered using the information provided answer
with "I don't know".

Context: You are a personnel recommending agent. Given the user required personnel, find the top 4 people with relevant experience
and background that fit the user's needs in a table format with also a score on the right on how much they match.

You will do this analysis from the user's list available below

User List: {user_connections_list}

User Query : {user_query}

Answer: """

prompt_template = PromptTemplate(
    input_variables=["user_connections_list","user_query"],
    template=template
)



claude_chain = LLMChain(prompt=prompt_template, llm=claude)

claude_output = claude_chain.run(user_connections_list=user_connections_list,user_query=user_query)




# Page Config
st.set_page_config(
    page_title="Image Upload App",
    page_icon="ðŸ“·",
    layout="wide",
    initial_sidebar_state="expanded",

)

# App Title
st.title("FoodSmith ðŸ“·")

# Columns
col1, col2 = st.columns(2)

# Custom CSS for Image Display
custom_css = """
    <style>
        .uploaded-image {
            max-width: 100%;
            height: auto;
        }
    </style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

# Image Upload
with col1:
    st.header("Upload an Image")
    uploaded_file = st.file_uploader(
        "Choose an image...", type=["jpg", "png", "jpeg"])

# Image Display
with col2:
    st.header("Preview")
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="Uploaded Image", use_column_width=True)


# # Additional Markdown and HTML Styling
# st.markdown("## **Image Analysis Options**")
# st.markdown("<hr/>", unsafe_allow_html=True)


# Loading Indicator for Analysis
if uploaded_file is not None:
    # result = main_function()
    # st.write(result)
    with st.spinner("Analyzing image..."):
        result = main_function()  # Run your backend main function

        # Simulate image analysis here
    st.success("Analysis complete!")

    st.write(result)
